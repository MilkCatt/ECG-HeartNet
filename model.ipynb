{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device for torch\n",
    "device = torch.device(\"cpu\")\n",
    "# MPS for Apple Silicon GPUs\n",
    "if torch.mps.is_available():\n",
    "   print(\"MPS is available\")\n",
    "   device = torch.device(\"mps\")\n",
    "\n",
    "# CUDA for Nvidia GPUs\n",
    "if torch.cuda.is_available():\n",
    "   print(\"CUDA is available\")\n",
    "   device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    for name, module in model.named_modules():\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        print(f\"{name}: {params} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader\n",
    "\n",
    "To investigate: Normalization or other transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeECG:\n",
    "    def __call__(self, tensor):\n",
    "        # Z-score normalization per lead\n",
    "        means = tensor.mean(dim=1, keepdim=True)\n",
    "        stds = tensor.std(dim=1, keepdim=True)\n",
    "        return (tensor - means) / (stds + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, path=\"data/ecg\", diagnoses='data/diagnoses.csv', transform=None):\n",
    "        # Load and prepare labels\n",
    "        self.labels_df = pd.read_csv(diagnoses)\n",
    "\n",
    "        self.labels_df['ID'] = self.labels_df['ID'].astype(str).str.replace(r'\\D', '', regex=True) # Remove the JS\n",
    "        self.labels_df.set_index('ID', inplace=True)\n",
    "        self.num_classes = self.labels_df.shape[1]\n",
    "        print(f'Number of classes: {self.num_classes}')\n",
    "\n",
    "        self.transform = transform\n",
    "        self.cache = {}\n",
    "\n",
    "    def get_pos_weights(self):\n",
    "        # Compute counts\n",
    "        pos_counts = self.labels_df.sum()\n",
    "        neg_counts = len(self.labels_df) - pos_counts\n",
    "\n",
    "        # Calculate pos_weight = #neg / #pos for each class\n",
    "        pos_weight = (neg_counts / pos_counts).values\n",
    "\n",
    "        # Move to device\n",
    "        pos_weight_tensor = torch.tensor(pos_weight, dtype=torch.float32, device=device)\n",
    "        return pos_weight_tensor\n",
    "    \n",
    "    def get_num_classes(self):\n",
    "        return self.num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.cache:\n",
    "            return self.cache[idx]\n",
    "        \n",
    "        try:\n",
    "            # Access the row through iloc of the index,\n",
    "            # Use the ID to make filepath\n",
    "            ID = self.labels_df.iloc[idx].name\n",
    "\n",
    "            file_path = f'data/ecg/{ID}.csv'\n",
    "            \n",
    "            # Load ECG data\n",
    "            df = pd.read_csv(file_path)\n",
    "            ecg_data = df.drop(columns=['time']).values\n",
    "            tensor = torch.tensor(ecg_data, dtype=torch.float32).T  # (leads, timesteps)\n",
    "            \n",
    "            if self.transform:\n",
    "                tensor = self.transform(tensor)\n",
    "                \n",
    "            # Get corresponding label\n",
    "\n",
    "            label_values = self.labels_df.loc[ID].values  # Get all label columns\n",
    "            label = torch.tensor(label_values, dtype=torch.float32)  # Use float for multi-label\n",
    "\n",
    "            return tensor, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {str(e)}\")\n",
    "            # Return zero tensor and -1 label placeholder\n",
    "            return torch.zeros((12, 5000), dtype=torch.float32), torch.full((self.num_classes,), -1, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ECGDataset(path=\"data/ecg\", diagnoses='data/diagnoses_balanced.csv')\n",
    "data, label = dataset.__getitem__(23423)\n",
    "print(data.shape)\n",
    "print(label.shape)\n",
    "dataset.get_pos_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGTransformer(nn.Module):\n",
    "    def __init__(self, d_model, num_classes=63, nhead=8, num_encoder_layers=2, dim_feedforward=2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=dim_feedforward, batch_first=True)\n",
    "\n",
    "        # Encoder stack\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.transformer(x)\n",
    "        # encoded shape: (batch_size, seq_len, d_model)\n",
    "        # Pick out only the last in the sequence for classification\n",
    "        encoded = encoded[:, -1, :]\n",
    "        result = self.classifier(encoded)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECGTransformer(d_model=12, nhead=4, num_classes=63, num_encoder_layers=6, dim_feedforward=512)\n",
    "print(model)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand((2, 5000, 12))\n",
    "out = model(inputs)\n",
    "print(out.shape)\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An embedding model \n",
    "that uses convolution\n",
    "\n",
    "Convolution turning 12 channels to 128, repeated to transfer forward 200ms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGEmbeddings_old(nn.Module):\n",
    "    def __init__(self, d_input, d_model, n_conv_layers=8):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(d_model if i>0 else d_input, d_model, 51, stride=1, padding='same')\n",
    "            for i in range(n_conv_layers)\n",
    "        ])\n",
    "        self.activation = nn.ReLU(inplace=False)  # Important for checkpointing\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.conv_layers)):\n",
    "            x = self.conv_layers[i](x)\n",
    "            if i < len(self.conv_layers) - 1:\n",
    "                x = self.activation(x)\n",
    "\n",
    "        if not x.requires_grad:\n",
    "            x = x.detach().requires_grad_(True)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGEmbeddings(nn.Module):\n",
    "    def __init__(self, d_input, d_model):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        in_channels = d_input\n",
    "        out_channels = d_input\n",
    "\n",
    "        # Dynamically adjust the number of channels to reach d_model\n",
    "        while out_channels < d_model:\n",
    "            out_channels = min(d_model, out_channels * 2)  # Double channels, but cap at d_model\n",
    "            self.conv_layers.append(nn.Conv1d(in_channels, out_channels, 1, stride=1, padding='same'))\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.activation = nn.ReLU(inplace=False)  # Important for checkpointing\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, conv in enumerate(self.conv_layers):\n",
    "            x = conv(x)\n",
    "            if i < len(self.conv_layers) - 1:  # Apply activation except for the last layer\n",
    "                x = self.activation(x)\n",
    "\n",
    "        if not x.requires_grad:\n",
    "            x = x.detach().requires_grad_(True)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = ECGEmbeddings(d_input=12, d_model=256)\n",
    "print(embedding_model)\n",
    "count_parameters(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining together embedding with transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGCombined(nn.Module):\n",
    "    def __init__(self, d_input, d_model, num_classes=63, nhead=8, num_encoder_layers=2, dim_feedforward=2048):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.embedding_model = ECGEmbeddings(d_input, d_model)\n",
    "        self.transformer = ECGTransformer(d_model, num_classes, nhead, num_encoder_layers, dim_feedforward)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_model(x)\n",
    "        x = x.permute(0, 2, 1)       # Reshape to (batch_size, seq_len, d_model)\n",
    "        x = self.transformer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, device, pos_weights=None, accum_steps=4, checkpoint_interval=256, lr=1e-4,\n",
    "                 resume_checkpoint=None):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.accum_steps = accum_steps\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        \n",
    "        # Initialize essential components\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.f1 = F1Score(task='multilabel', num_labels=self.model.num_classes, average=None)\n",
    "        self.loss = nn.BCEWithLogitsLoss(pos_weight=pos_weights)   \n",
    "        self.accum_loss = 0.0\n",
    "        self.loss_history = []\n",
    "        self.acc_history = []\n",
    "        self.batch_count = 0\n",
    "        self.start_epoch = 0\n",
    "        self.start_batch = 0\n",
    "\n",
    "        if resume_checkpoint:\n",
    "            self._load_checkpoint(resume_checkpoint)\n",
    "\n",
    "    def _load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load training state from checkpoint\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)\n",
    "        \n",
    "        # Essential parameters\n",
    "        self.model.load_state_dict(checkpoint['model_state'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        \n",
    "        # Training progress\n",
    "        self.loss_history = checkpoint['loss_history']\n",
    "        self.acc_history = checkpoint['acc_history']\n",
    "        self.batch_count = checkpoint.get('batch_count', 0)\n",
    "        self.start_epoch = checkpoint['epoch']\n",
    "        self.start_batch = checkpoint.get('batch', 0) + 1\n",
    "        \n",
    "        # Configurations\n",
    "        self.checkpoint_interval = checkpoint.get('checkpoint_interval', \n",
    "                                                 self.checkpoint_interval)\n",
    "        \n",
    "        print(f\"Resuming from epoch {self.start_epoch} batch {self.start_batch}\")\n",
    "\n",
    "    def train(self, train_dataloader, test_dataloader, num_epochs, save_path=\"training_progress\"):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        self.model.train()\n",
    "        \n",
    "        for epoch in range(self.start_epoch, num_epochs):\n",
    "            for batch_idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "                if batch_idx < self.start_batch:\n",
    "                    continue\n",
    "                \n",
    "                # Forward pass\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss(outputs, labels) / self.accum_steps\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Every batch\n",
    "                self.accum_loss += loss.item()\n",
    "                self.batch_count += 1\n",
    "                \n",
    "                # Every accum_steps\n",
    "                if (batch_idx + 1) % self.accum_steps == 0:\n",
    "                    self._update_parameters()\n",
    "                    \n",
    "                    # Save loss\n",
    "                    avg_loss = self.accum_loss\n",
    "                    self.loss_history.append([self.batch_count, avg_loss])\n",
    "                    self.accum_loss = 0.0\n",
    "\n",
    "                    print(f\"Epoch {epoch+1}/{num_epochs} | Batch {batch_idx+1}/{len(train_dataloader)} | \"\n",
    "                        f\"Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "                # Every checkpoint_interval\n",
    "                if self.batch_count % self.checkpoint_interval == 0:\n",
    "                    acc = self.evaluate(test_dataloader)\n",
    "                    self.acc_history.append([self.batch_count, acc])\n",
    "                    self._save_checkpoint(save_path, epoch, batch_idx)\n",
    "                \n",
    "                del inputs, labels, outputs, loss\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_samples = 0\n",
    "        num_classes = self.model.num_classes\n",
    "        mismatches_per_class = torch.zeros(num_classes, device=self.device)\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                # Get binary predictions (0 or 1) using threshold\n",
    "                predicted = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "\n",
    "                all_preds.append(predicted.cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "                \n",
    "                # Track mismatches per class\n",
    "                mismatches_per_class += (predicted != labels).sum(dim=0).float()\n",
    "                total_samples += inputs.size(0)  # Batch size\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat(all_preds)\n",
    "        all_labels = torch.cat(all_labels)\n",
    "\n",
    "        # Accuracy metrics\n",
    "        f1_score_per_class = self.f1(all_preds, all_labels).cpu().numpy()\n",
    "        print(f\"F1 Score per class: {f1_score_per_class}\")\n",
    "        hamming_loss_per_class = mismatches_per_class.cpu().numpy() / total_samples\n",
    "\n",
    "        return {\n",
    "            \"f1_per_class\": f1_score_per_class,\n",
    "            \"hamming_loss_per_class\": hamming_loss_per_class\n",
    "        }\n",
    "    \n",
    "    def _update_parameters(self):\n",
    "        \"\"\"Update model parameters with gradient clipping\"\"\"\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def _save_checkpoint(self, path, epoch, batch_idx):\n",
    "        \"\"\"Save model and training state\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'batch': batch_idx,\n",
    "            'batch_count': self.batch_count,\n",
    "            'checkpoint_interval': self.checkpoint_interval,\n",
    "            'model_state': self.model.state_dict(),\n",
    "            'optimizer_state': self.optimizer.state_dict(),\n",
    "            'loss_history': self.loss_history,\n",
    "            'acc_history': self.acc_history\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, f\"{path}/checkpoint_ep{epoch}_b{batch_idx}.pt\")\n",
    "        print(f\"\\nCheckpoint saved at epoch {epoch+1} batch {batch_idx+1}\")\n",
    "\n",
    "        np.save(f\"{path}/loss_history.npy\", np.array(self.loss_history))\n",
    "        np.save(f\"{path}/acc_history.npy\", np.array(self.acc_history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Go Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta\n",
    "diagnoses = \"data/diagnoses_balanced.csv\"\n",
    "save_path = \"training_progress/new_balanced\"\n",
    "checkpoint_interval = 1024\n",
    "\n",
    "# Hyperparameters\n",
    "add_pos_weights = True\n",
    "normalize = True\n",
    "batch_size = 4\n",
    "accum_steps = 4         # Updates every accum_steps batches\n",
    "starting_lr = 1e-5      # For resuming, set lr (could be lower) at the resume cell below\n",
    "\n",
    "# Embeddings parameters\n",
    "d_input = 12\n",
    "d_model = 128\n",
    "\n",
    "# Transformer parameters\n",
    "nhead = 4\n",
    "num_encoder_layers = 2\n",
    "dim_feedforward = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_dataset = ECGDataset(diagnoses=diagnoses, transform=NormalizeECG() if normalize else None)\n",
    "pos_weights = ecg_dataset.get_pos_weights() if add_pos_weights else None\n",
    "num_classes = ecg_dataset.get_num_classes()\n",
    "\n",
    "train_dataset, test_dataset, val_dataset = random_split(\n",
    "                                            ecg_dataset, [len(ecg_dataset) - 1000, 500, 500])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECGCombined(d_input=d_input, d_model=d_model, num_classes=num_classes, nhead=nhead, num_encoder_layers=num_encoder_layers, dim_feedforward=dim_feedforward).to(device)\n",
    "trainer = Trainer(model, device, accum_steps=accum_steps, lr=starting_lr, pos_weights=pos_weights, checkpoint_interval=checkpoint_interval)\n",
    "trainer.train(train_dataloader, test_dataloader, num_epochs=1, save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume from a checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_from = f\"{save_path}/checkpoint_ep0_b2047.pt\"\n",
    "resume_lr = 1e-8\n",
    "\n",
    "model = ECGCombined(d_input=d_input, d_model=d_model, num_classes=num_classes, nhead=nhead, num_encoder_layers=num_encoder_layers, dim_feedforward=dim_feedforward).to(device)\n",
    "trainer = Trainer(model, device, accum_steps=accum_steps, lr=starting_lr, pos_weights=pos_weights, checkpoint_interval=checkpoint_interval, resume_checkpoint=resume_from)\n",
    "trainer.train(train_dataloader, test_dataloader, num_epochs=1, save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = np.load(f'{save_path}/loss_history.npy', allow_pickle=True)  # Load loss history\n",
    "acc_history = np.load(f'{save_path}/acc_history.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss history plot\n",
    "x = [epoch[0] for epoch in loss_history]\n",
    "y = [epoch[1] for epoch in loss_history]\n",
    "plt.plot(x, y, label='Loss')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score plot\n",
    "x = [epoch[0] for epoch in acc_history]\n",
    "y = [epoch[1]['f1_per_class'] for epoch in acc_history]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Batches')\n",
    "plt.legend([f'Class {i}' for i in range(len(y[0]))])\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamming accuracy plot\n",
    "x = [epoch[0] for epoch in acc_history]\n",
    "y = [epoch[1]['hamming_loss_per_class'] for epoch in acc_history]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.legend([f'Class {i}' for i in range(len(y[0]))])\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Hamming Loss')\n",
    "#plt.yscale('log')\n",
    "plt.title('Hamming Loss per class')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
