{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Define device for torch\n",
    "device = torch.device(\"cpu\")\n",
    "# MPS for Apple Silicon GPUs\n",
    "if torch.mps.is_available():\n",
    "   print(\"MPS is available\")\n",
    "   device = torch.device(\"mps\")\n",
    "\n",
    "# CUDA for Nvidia GPUs\n",
    "if torch.cuda.is_available():\n",
    "   print(\"CUDA is available\")\n",
    "   device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    for name, module in model.named_modules():\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        print(f\"{name}: {params} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader\n",
    "\n",
    "To investigate: Normalization or other transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeECG:\n",
    "    def __call__(self, tensor):\n",
    "        # Z-score normalization per lead\n",
    "        means = tensor.mean(dim=1, keepdim=True)\n",
    "        stds = tensor.std(dim=1, keepdim=True)\n",
    "        return (tensor - means) / (stds + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, path=\"data/WFDBRecords\", diagnoses='data/diagnoses.csv', transform=None):\n",
    "        # Store file paths with cleaned IDs\n",
    "        self.file_info = []  # List of tuples (cleaned_id, file_path)\n",
    "        \n",
    "        # Extract numeric IDs from filenames\n",
    "        for root, _, files in os.walk(path):\n",
    "            for file in files:\n",
    "                if file.endswith('.csv'):\n",
    "                    # Extract numeric part from filename (e.g., \"abc00001.csv\" -> \"00001\")\n",
    "                    cleaned_id = re.sub(r'\\D', '', file)\n",
    "                    self.file_info.append((\n",
    "                        cleaned_id,\n",
    "                        os.path.join(root, file)\n",
    "                    ))\n",
    "\n",
    "        # Load and prepare labels\n",
    "        self.labels_df = pd.read_csv(diagnoses)\n",
    "        # Clean IDs in both DataFrame and our file list\n",
    "        self.labels_df['ID'] = self.labels_df['ID'].astype(str).str.replace(r'\\D', '', regex=True)\n",
    "        self.labels_df.set_index('ID', inplace=True)\n",
    "\n",
    "        # Filter out files without corresponding labels\n",
    "        valid_ids = set(self.labels_df.index)\n",
    "        self.file_info = [(i, p) for i, p in self.file_info if i in valid_ids]\n",
    "\n",
    "        self.transform = transform\n",
    "        self.cache = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if len(self.file_info) == 0:\n",
    "            raise ValueError(\"Dataset is empty. Check file paths and diagnoses.csv.\")\n",
    "    \n",
    "        if idx in self.cache:\n",
    "            return self.cache[idx]\n",
    "\n",
    "        cleaned_id, file_path = self.file_info[idx]\n",
    "        \n",
    "        try:\n",
    "            # Load ECG data\n",
    "            df = pd.read_csv(file_path)\n",
    "            ecg_data = df.drop(columns=['time']).values\n",
    "            tensor = torch.tensor(ecg_data, dtype=torch.float32).T  # (leads, timesteps)\n",
    "            \n",
    "            if self.transform:\n",
    "                tensor = self.transform(tensor)\n",
    "                \n",
    "            # Get corresponding label\n",
    "            label_values = self.labels_df.loc[cleaned_id].values  # Get all label columns\n",
    "            label = torch.tensor(label_values, dtype=torch.float32)  # Use float for multi-label\n",
    "\n",
    "            return tensor, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {str(e)}\")\n",
    "            # Return zero tensor and -1 label placeholder\n",
    "            return torch.zeros((12, 5000)), torch.tensor(-1, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 5000])\n",
      "torch.Size([94])\n"
     ]
    }
   ],
   "source": [
    "dataset = ECGDataset()\n",
    "data, label = dataset.__getitem__(0)\n",
    "print(data.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGTransformer(nn.Module):\n",
    "    def __init__(self, d_model, num_classes=63, nhead=8, num_encoder_layers=2, dim_feedforward=2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=dim_feedforward, batch_first=True)\n",
    "\n",
    "        # Encoder stack\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.transformer(x)\n",
    "        # encoded shape: (batch_size, seq_len, d_model)\n",
    "        # Pick out only the last in the sequence for classification\n",
    "        encoded = encoded[:, -1, :]\n",
    "        result = self.classifier(encoded)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECGTransformer(\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=12, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=12, bias=True)\n",
      "        (norm1): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=12, out_features=63, bias=True)\n",
      ")\n",
      ": 81723 parameters\n",
      "transformer: 80904 parameters\n",
      "transformer.layers: 80904 parameters\n",
      "transformer.layers.0: 13484 parameters\n",
      "transformer.layers.0.self_attn: 624 parameters\n",
      "transformer.layers.0.self_attn.out_proj: 156 parameters\n",
      "transformer.layers.0.linear1: 6656 parameters\n",
      "transformer.layers.0.dropout: 0 parameters\n",
      "transformer.layers.0.linear2: 6156 parameters\n",
      "transformer.layers.0.norm1: 24 parameters\n",
      "transformer.layers.0.norm2: 24 parameters\n",
      "transformer.layers.0.dropout1: 0 parameters\n",
      "transformer.layers.0.dropout2: 0 parameters\n",
      "transformer.layers.1: 13484 parameters\n",
      "transformer.layers.1.self_attn: 624 parameters\n",
      "transformer.layers.1.self_attn.out_proj: 156 parameters\n",
      "transformer.layers.1.linear1: 6656 parameters\n",
      "transformer.layers.1.dropout: 0 parameters\n",
      "transformer.layers.1.linear2: 6156 parameters\n",
      "transformer.layers.1.norm1: 24 parameters\n",
      "transformer.layers.1.norm2: 24 parameters\n",
      "transformer.layers.1.dropout1: 0 parameters\n",
      "transformer.layers.1.dropout2: 0 parameters\n",
      "transformer.layers.2: 13484 parameters\n",
      "transformer.layers.2.self_attn: 624 parameters\n",
      "transformer.layers.2.self_attn.out_proj: 156 parameters\n",
      "transformer.layers.2.linear1: 6656 parameters\n",
      "transformer.layers.2.dropout: 0 parameters\n",
      "transformer.layers.2.linear2: 6156 parameters\n",
      "transformer.layers.2.norm1: 24 parameters\n",
      "transformer.layers.2.norm2: 24 parameters\n",
      "transformer.layers.2.dropout1: 0 parameters\n",
      "transformer.layers.2.dropout2: 0 parameters\n",
      "transformer.layers.3: 13484 parameters\n",
      "transformer.layers.3.self_attn: 624 parameters\n",
      "transformer.layers.3.self_attn.out_proj: 156 parameters\n",
      "transformer.layers.3.linear1: 6656 parameters\n",
      "transformer.layers.3.dropout: 0 parameters\n",
      "transformer.layers.3.linear2: 6156 parameters\n",
      "transformer.layers.3.norm1: 24 parameters\n",
      "transformer.layers.3.norm2: 24 parameters\n",
      "transformer.layers.3.dropout1: 0 parameters\n",
      "transformer.layers.3.dropout2: 0 parameters\n",
      "transformer.layers.4: 13484 parameters\n",
      "transformer.layers.4.self_attn: 624 parameters\n",
      "transformer.layers.4.self_attn.out_proj: 156 parameters\n",
      "transformer.layers.4.linear1: 6656 parameters\n",
      "transformer.layers.4.dropout: 0 parameters\n",
      "transformer.layers.4.linear2: 6156 parameters\n",
      "transformer.layers.4.norm1: 24 parameters\n",
      "transformer.layers.4.norm2: 24 parameters\n",
      "transformer.layers.4.dropout1: 0 parameters\n",
      "transformer.layers.4.dropout2: 0 parameters\n",
      "transformer.layers.5: 13484 parameters\n",
      "transformer.layers.5.self_attn: 624 parameters\n",
      "transformer.layers.5.self_attn.out_proj: 156 parameters\n",
      "transformer.layers.5.linear1: 6656 parameters\n",
      "transformer.layers.5.dropout: 0 parameters\n",
      "transformer.layers.5.linear2: 6156 parameters\n",
      "transformer.layers.5.norm1: 24 parameters\n",
      "transformer.layers.5.norm2: 24 parameters\n",
      "transformer.layers.5.dropout1: 0 parameters\n",
      "transformer.layers.5.dropout2: 0 parameters\n",
      "classifier: 819 parameters\n"
     ]
    }
   ],
   "source": [
    "model = ECGTransformer(d_model=12, nhead=4, num_classes=63, num_encoder_layers=6, dim_feedforward=512)\n",
    "print(model)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 63])\n",
      "tensor([ 1.0182, -0.9489,  0.2784,  0.9533, -0.1510, -0.6213,  0.5716, -0.4948,\n",
      "        -0.2717, -0.6362,  0.0804,  0.9113, -0.1880,  0.4689, -0.2032,  0.1908,\n",
      "         0.3878, -0.3923, -0.0663, -0.0287, -0.8647,  0.4793,  0.2846, -0.3575,\n",
      "        -0.6002,  0.2385, -0.6557, -0.3875, -0.0052,  0.8377, -1.0622, -0.9162,\n",
      "        -0.4564, -1.1498,  0.9539,  0.4649,  1.3470, -0.8705,  0.1994,  1.0465,\n",
      "        -0.7717, -0.5953,  0.4582, -0.1437, -0.9721, -0.4984, -1.4124,  0.3614,\n",
      "        -0.7855,  0.5249,  0.2516,  0.2192,  0.5857, -0.3805, -0.7895, -0.4147,\n",
      "         0.3128, -0.8980,  0.2463, -0.7288, -0.8712,  0.3469,  0.1505],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand((2, 5000, 12))\n",
    "out = model(inputs)\n",
    "print(out.shape)\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An embedding model \n",
    "that uses convolution\n",
    "\n",
    "Convolution turning 12 channels to 128, repeated to transfer forward 200ms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGEmbeddings(nn.Module):\n",
    "    def __init__(self, d_input, d_model):\n",
    "        super().__init__()\n",
    "        # Keep original layers\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(d_model if i>0 else d_input, d_model, 50, stride=1, padding='same')\n",
    "            for i in range(8)\n",
    "        ])\n",
    "        self.activation = nn.ReLU(inplace=False)  # Important for checkpointing\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split into gradient checkpoint blocks\n",
    "        def run_block(x, start, end):\n",
    "            for i in range(start, end+1):\n",
    "                x = self.conv_layers[i](x)\n",
    "                x = self.activation(x)\n",
    "            return x\n",
    "\n",
    "        if not x.requires_grad:\n",
    "            x = x.detach().requires_grad_(True)\n",
    "        \n",
    "        # Checkpoint groups of layers\n",
    "        x = torch.utils.checkpoint.checkpoint(run_block, x, 0, 3, use_reentrant=False)  # Layers 0-3\n",
    "        x = torch.utils.checkpoint.checkpoint(run_block, x, 4, 7, use_reentrant=False)  # Layers 4-7\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECGEmbeddings(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): Conv1d(12, 512, kernel_size=(50,), stride=(1,), padding=same)\n",
      "    (1-7): 7 x Conv1d(512, 512, kernel_size=(50,), stride=(1,), padding=same)\n",
      "  )\n",
      "  (activation): ReLU()\n",
      ")\n",
      ": 92061696 parameters\n",
      "conv_layers: 92061696 parameters\n",
      "conv_layers.0: 307712 parameters\n",
      "conv_layers.1: 13107712 parameters\n",
      "conv_layers.2: 13107712 parameters\n",
      "conv_layers.3: 13107712 parameters\n",
      "conv_layers.4: 13107712 parameters\n",
      "conv_layers.5: 13107712 parameters\n",
      "conv_layers.6: 13107712 parameters\n",
      "conv_layers.7: 13107712 parameters\n",
      "activation: 0 parameters\n"
     ]
    }
   ],
   "source": [
    "embedding_model = ECGEmbeddings(d_input = 12, d_model=512)\n",
    "print(embedding_model)\n",
    "count_parameters(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining together embedding with transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGCombined(nn.Module):\n",
    "    def __init__(self, d_input, d_model, num_classes=63, nhead=8, num_encoder_layers=2, dim_feedforward=2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_model = ECGEmbeddings(d_input, d_model)\n",
    "        self.transformer = ECGTransformer(d_model, num_classes, nhead, num_encoder_layers, dim_feedforward)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_model(x)\n",
    "        x = x.permute(0, 2, 1)       # Reshape to (batch_size, seq_len, d_model)\n",
    "        x = self.transformer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, device, accum_steps=4, checkpoint_interval=100, lr = 1e-4,\n",
    "                 resume_checkpoint=None):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.accum_steps = accum_steps\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        \n",
    "        # Initialize essential components first\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.loss_history = []\n",
    "        self.acc_history = []\n",
    "        self.batch_count = 0\n",
    "        self.start_epoch = 0\n",
    "        self.start_batch = 0\n",
    "\n",
    "        # Override with checkpoint if provided\n",
    "        if resume_checkpoint:\n",
    "            self._load_checkpoint(resume_checkpoint)\n",
    "\n",
    "    def _load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load training state from checkpoint\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        \n",
    "        # Essential parameters\n",
    "        self.model.load_state_dict(checkpoint['model_state'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        self.scaler.load_state_dict(checkpoint['scaler_state'])\n",
    "        \n",
    "        # Training progress\n",
    "        self.loss_history = checkpoint['loss_history']\n",
    "        self.acc_history = checkpoint['acc_history']\n",
    "        self.batch_count = checkpoint.get('batch_count', 0)\n",
    "        self.start_epoch = checkpoint['epoch']  # Resume from same epoch\n",
    "        self.start_batch = checkpoint.get('batch', 0) + 1  # Next batch\n",
    "        \n",
    "        # Configurations (optional but recommended)\n",
    "        self.checkpoint_interval = checkpoint.get('checkpoint_interval', \n",
    "                                                 self.checkpoint_interval)\n",
    "        \n",
    "        print(f\"Resuming from epoch {self.start_epoch} batch {self.start_batch}\")\n",
    "\n",
    "    def loss(self, output, target):\n",
    "        return F.binary_cross_entropy_with_logits(output, target.float())\n",
    "\n",
    "    def train(self, train_dataloader, test_dataloader, num_epochs, save_path=\"training_progress\"):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        self.model.train()\n",
    "        \n",
    "        # Start from the last checkpoint epoch\n",
    "        print(\"Hi\")\n",
    "        for epoch in range(self.start_epoch, num_epochs):\n",
    "            print(\"Hello\")\n",
    "            # Skip batches we've already processed in this epoch\n",
    "            for batch_idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "                if batch_idx < self.start_batch:\n",
    "                    continue\n",
    "                # Forward pass\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    outputs = self.model(inputs)\n",
    "                    loss = self.loss(outputs, labels) / self.accum_steps\n",
    "\n",
    "                # Backward pass\n",
    "                self.scaler.scale(loss).backward()\n",
    "                \n",
    "                # Gradient accumulation\n",
    "                if (batch_idx + 1) % self.accum_steps == 0:\n",
    "                    self._update_parameters()\n",
    "                \n",
    "                # Logging and checkpointing\n",
    "                current_loss = loss.item() * self.accum_steps\n",
    "                self.loss_history.append(current_loss)\n",
    "                self.batch_count += 1\n",
    "\n",
    "                # Print every batch\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} | Batch {batch_idx+1}/{len(train_dataloader)} | \"\n",
    "                    f\"Loss: {current_loss:.4f}\")\n",
    "\n",
    "                # Save checkpoint\n",
    "                if self.batch_count % self.checkpoint_interval == 0:\n",
    "                    acc = self.evaluate(test_dataloader)\n",
    "                    self.acc_history.append([self.batch_count, acc])\n",
    "                    self._save_checkpoint(save_path, epoch, batch_idx)\n",
    "                \n",
    "                del inputs, labels, outputs, loss\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_mismatches = 0.0\n",
    "        total_labels = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                # Get binary predictions (0 or 1) using threshold\n",
    "                predicted = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "                \n",
    "                # Calculate mismatches\n",
    "                mismatches = (predicted != labels).float().sum().item()\n",
    "                total_mismatches += mismatches\n",
    "                total_labels += labels.numel()  # Total labels = batch_size * num_classes\n",
    "\n",
    "        hamming_loss = total_mismatches / total_labels\n",
    "        print(f'Hamming Loss: {hamming_loss:.4f}')\n",
    "        return hamming_loss\n",
    "\n",
    "\n",
    "    def _update_parameters(self):\n",
    "        \"\"\"Update model parameters with gradient clipping\"\"\"\n",
    "        self.scaler.unscale_(self.optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 5.0)\n",
    "        self.scaler.step(self.optimizer)\n",
    "        self.scaler.update()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def _save_checkpoint(self, path, epoch, batch_idx):\n",
    "        \"\"\"Save model and training state\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'batch': batch_idx,\n",
    "            'batch_count': self.batch_count,\n",
    "            'checkpoint_interval': self.checkpoint_interval,\n",
    "            'model_state': self.model.state_dict(),\n",
    "            'optimizer_state': self.optimizer.state_dict(),\n",
    "            'loss_history': self.loss_history,\n",
    "            'acc_history': self.acc_history,\n",
    "            'scaler_state': self.scaler.state_dict()\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, f\"{path}/checkpoint_ep{epoch}_b{batch_idx}.pt\")\n",
    "        print(f\"\\nCheckpoint saved at epoch {epoch+1} batch {batch_idx+1}\")\n",
    "        \n",
    "        # Save loss history separately for easy plotting\n",
    "        np.save(f\"{path}/loss_history.npy\", np.array(self.loss_history))\n",
    "        np.save(f\"{path}/acc_history.npy\", np.array(self.acc_history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Go Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_dataset = ECGDataset(transform=None)\n",
    "train_dataset, test_dataset, val_dataset = random_split(\n",
    "                                            ecg_dataset, [len(ecg_dataset) - 1000, 500, 500], \n",
    "                                            torch.Generator().manual_seed(42))\n",
    "\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qn/2b8ykc751b396vqz3_bbcqlw0000gn/T/ipykernel_11907/2586268991.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      "Hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/conv.py:370: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Convolution.cpp:1037.)\n",
      "  return F.conv1d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 1/8638 | Loss: 0.7124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 2/8638 | Loss: 0.7103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 3/8638 | Loss: 0.7207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 4/8638 | Loss: 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 5/8638 | Loss: 0.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ECGCombined(d_input=12, d_model=128, num_classes=94, nhead=4, num_encoder_layers=2, dim_feedforward=256).to(device)\n",
    "trainer = Trainer(model, device, accum_steps=4, lr=1e-4)\n",
    "trainer.train(train_dataloader, test_dataloader, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume from a checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qn/2b8ykc751b396vqz3_bbcqlw0000gn/T/ipykernel_32059/2586268991.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from epoch 0 batch 1100\n",
      "Hi\n",
      "Hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/conv.py:370: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/Convolution.cpp:1037.)\n",
      "  return F.conv1d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 1101/8638 | Loss: 0.1097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 1102/8638 | Loss: 0.0998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 1103/8638 | Loss: 0.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 1104/8638 | Loss: 0.0896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 1105/8638 | Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 1106/8638 | Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Batch 1107/8638 | Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m ECGCombined(d_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m94\u001b[39m, nhead\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_encoder_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim_feedforward\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, device, accum_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, resume_checkpoint\u001b[38;5;241m=\u001b[39mresume_from, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 70\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_dataloader, test_dataloader, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Gradient accumulation\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccum_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Logging and checkpointing\u001b[39;00m\n\u001b[1;32m     73\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccum_steps\n",
      "Cell \u001b[0;32mIn[13], line 115\u001b[0m, in \u001b[0;36mTrainer._update_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39munscale_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer)\n\u001b[1;32m    114\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m5.0\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/amp/grad_scaler.py:384\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke ``unscale_(optimizer)`` followed by parameter update, if gradients are not infs/NaN.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m:meth:`step` carries out the following two operations:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    Closure use is not currently supported.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enabled:\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosure\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClosure use is not currently supported if GradScaler is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/adam.py:246\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    234\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    236\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    237\u001b[0m         group,\n\u001b[1;32m    238\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         state_steps,\n\u001b[1;32m    244\u001b[0m     )\n\u001b[0;32m--> 246\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/optimizer.py:147\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/adam.py:933\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 933\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/adam.py:509\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    507\u001b[0m         param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstep\n\u001b[1;32m    512\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstep\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/optim/optimizer.py:94\u001b[0m, in \u001b[0;36m_get_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resume_from = \"training_progress/checkpoint_ep0_b1099.pt\"\n",
    "\n",
    "model = ECGCombined(d_input=12, d_model=128, num_classes=94, nhead=4, num_encoder_layers=2, dim_feedforward=256).to(device)\n",
    "trainer = Trainer(model, device, accum_steps=4, resume_checkpoint=resume_from, lr=1e-6)\n",
    "trainer.train(train_dataloader, test_dataloader, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"training_progress/checkpoint_ep0_b1399.pt\")\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(checkpoint['loss_history'], label='Loss')\n",
    "ax1.set_xlabel('Batch')\n",
    "ax1.set_ylabel('Training Loss')\n",
    "ax1.set_title('Training Loss and Accuracy')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot([x[0] for x in checkpoint['acc_history']], [x[1] for x in checkpoint['acc_history']], color='red', label='Accuracy')\n",
    "ax2.set_ylabel('Hamming Loss')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
