{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device for torch\n",
    "device = torch.device(\"cpu\")\n",
    "# MPS for Apple Silicon GPUs\n",
    "if torch.mps.is_available():\n",
    "   print(\"MPS is available\")\n",
    "   device = torch.device(\"mps\")\n",
    "\n",
    "# CUDA for Nvidia GPUs\n",
    "if torch.cuda.is_available():\n",
    "   print(\"CUDA is available\")\n",
    "   device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    for name, module in model.named_modules():\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        print(f\"{name}: {params} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader\n",
    "\n",
    "To investigate: Normalization or other transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeECG:\n",
    "    def __call__(self, tensor):\n",
    "        # Z-score normalization per lead\n",
    "        means = tensor.mean(dim=1, keepdim=True)\n",
    "        stds = tensor.std(dim=1, keepdim=True)\n",
    "        return (tensor - means) / (stds + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, path=\"data/ecg\", diagnoses='data/diagnoses.csv', transform=None):\n",
    "        # Load and prepare labels\n",
    "        self.labels_df = pd.read_csv(diagnoses)\n",
    "\n",
    "        self.labels_df['ID'] = self.labels_df['ID'].astype(str).str.replace(r'\\D', '', regex=True) # Remove the JS\n",
    "        self.labels_df.set_index('ID', inplace=True)\n",
    "        self.num_classes = self.labels_df.shape[1]\n",
    "        print(f'Number of classes: {self.num_classes}')\n",
    "\n",
    "        self.transform = transform\n",
    "        self.cache = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.cache:\n",
    "            return self.cache[idx]\n",
    "        \n",
    "        try:\n",
    "            # Access the row through iloc of the index,\n",
    "            # Use the ID to make filepath\n",
    "            ID = self.labels_df.iloc[idx].name\n",
    "\n",
    "            file_path = f'data/ecg/{ID}.csv'\n",
    "            \n",
    "            # Load ECG data\n",
    "            df = pd.read_csv(file_path)\n",
    "            ecg_data = df.drop(columns=['time']).values\n",
    "            tensor = torch.tensor(ecg_data, dtype=torch.float32).T  # (leads, timesteps)\n",
    "            \n",
    "            if self.transform:\n",
    "                tensor = self.transform(tensor)\n",
    "                \n",
    "            # Get corresponding label\n",
    "\n",
    "            label_values = self.labels_df.loc[ID].values  # Get all label columns\n",
    "            label = torch.tensor(label_values, dtype=torch.float32)  # Use float for multi-label\n",
    "\n",
    "            return tensor, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {str(e)}\")\n",
    "            # Return zero tensor and -1 label placeholder\n",
    "            return torch.zeros((12, 5000), dtype=torch.float32), torch.full((self.num_classes,), -1, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ECGDataset()\n",
    "data, label = dataset.__getitem__(23423)\n",
    "print(data.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGTransformer(nn.Module):\n",
    "    def __init__(self, d_model, num_classes=63, nhead=8, num_encoder_layers=2, dim_feedforward=2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=dim_feedforward, batch_first=True)\n",
    "\n",
    "        # Encoder stack\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.transformer(x)\n",
    "        # encoded shape: (batch_size, seq_len, d_model)\n",
    "        # Pick out only the last in the sequence for classification\n",
    "        encoded = encoded[:, -1, :]\n",
    "        result = self.classifier(encoded)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECGTransformer(d_model=12, nhead=4, num_classes=63, num_encoder_layers=6, dim_feedforward=512)\n",
    "print(model)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand((2, 5000, 12))\n",
    "out = model(inputs)\n",
    "print(out.shape)\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An embedding model \n",
    "that uses convolution\n",
    "\n",
    "Convolution turning 12 channels to 128, repeated to transfer forward 200ms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGEmbeddings(nn.Module):\n",
    "    def __init__(self, d_input, d_model, n_conv_layers=3):\n",
    "        super().__init__()\n",
    "        # Keep original layers\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(d_model if i>0 else d_input, d_model, 51, stride=1, padding='same')\n",
    "            for i in range(n_conv_layers)\n",
    "        ])\n",
    "        self.activation = nn.ReLU(inplace=False)  # Important for checkpointing\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.conv_layers)):\n",
    "            x = self.conv_layers[i](x)\n",
    "            if i < len(self.conv_layers) - 1:\n",
    "                x = self.activation(x)\n",
    "\n",
    "        if not x.requires_grad:\n",
    "            x = x.detach().requires_grad_(True)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = ECGEmbeddings(d_input = 12, d_model=512)\n",
    "print(embedding_model)\n",
    "count_parameters(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining together embedding with transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGCombined(nn.Module):\n",
    "    def __init__(self, d_input, d_model, num_classes=63, nhead=8, num_encoder_layers=2, dim_feedforward=2048):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.embedding_model = ECGEmbeddings(d_input, d_model)\n",
    "        self.transformer = ECGTransformer(d_model, num_classes, nhead, num_encoder_layers, dim_feedforward)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_model(x)\n",
    "        x = x.permute(0, 2, 1)       # Reshape to (batch_size, seq_len, d_model)\n",
    "        x = self.transformer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, device, accum_steps=4, checkpoint_interval=256, lr = 1e-4,\n",
    "                 resume_checkpoint=None):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.accum_steps = accum_steps\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        \n",
    "        # Initialize essential components first\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr * accum_steps)\n",
    "        self.loss_history = []\n",
    "        self.acc_history = []\n",
    "        self.batch_count = 0\n",
    "        self.start_epoch = 0\n",
    "        self.start_batch = 0\n",
    "\n",
    "        # Override with checkpoint if provided\n",
    "        if resume_checkpoint:\n",
    "            self._load_checkpoint(resume_checkpoint)\n",
    "\n",
    "    def _load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load training state from checkpoint\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "        \n",
    "        # Essential parameters\n",
    "        self.model.load_state_dict(checkpoint['model_state'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        self.scaler.load_state_dict(checkpoint['scaler_state'])\n",
    "        \n",
    "        # Training progress\n",
    "        self.loss_history = checkpoint['loss_history']\n",
    "        self.acc_history = checkpoint['acc_history']\n",
    "        self.batch_count = checkpoint.get('batch_count', 0)\n",
    "        self.start_epoch = checkpoint['epoch']  # Resume from same epoch\n",
    "        self.start_batch = checkpoint.get('batch', 0) + 1  # Next batch\n",
    "        \n",
    "        # Configurations (optional but recommended)\n",
    "        self.checkpoint_interval = checkpoint.get('checkpoint_interval', \n",
    "                                                 self.checkpoint_interval)\n",
    "        \n",
    "        print(f\"Resuming from epoch {self.start_epoch} batch {self.start_batch}\")\n",
    "\n",
    "    def loss(self, output, target):\n",
    "        return F.binary_cross_entropy_with_logits(output, target.float())\n",
    "\n",
    "    def train(self, train_dataloader, test_dataloader, num_epochs, save_path=\"training_progress\"):\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        self.model.train()\n",
    "        \n",
    "        # Start from the last checkpoint epoch\n",
    "        for epoch in range(self.start_epoch, num_epochs):\n",
    "            # Skip batches we've already processed in this epoch\n",
    "            for batch_idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "                if batch_idx < self.start_batch:\n",
    "                    continue\n",
    "                # Forward pass\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    outputs = self.model(inputs)\n",
    "                    loss = self.loss(outputs, labels) / self.accum_steps\n",
    "\n",
    "                # Backward pass\n",
    "                self.scaler.scale(loss).backward()\n",
    "                \n",
    "                # Gradient accumulation\n",
    "                if (batch_idx + 1) % self.accum_steps == 0:\n",
    "                    self._update_parameters()\n",
    "                \n",
    "                # Logging and checkpointing\n",
    "                current_loss = loss.item() * self.accum_steps\n",
    "                self.loss_history.append(current_loss)\n",
    "                self.batch_count += 1\n",
    "\n",
    "                # Print every accum steps\n",
    "                if self.batch_count % self.accum_steps == 0: \n",
    "                    print(f\"Epoch {epoch+1}/{num_epochs} | Batch {batch_idx+1}/{len(train_dataloader)} | \"\n",
    "                        f\"Loss: {current_loss:.4f}\")\n",
    "\n",
    "                # Save checkpoint\n",
    "                if self.batch_count % self.checkpoint_interval == 0:\n",
    "                    acc = self.evaluate(test_dataloader)\n",
    "                    self.acc_history.append([self.batch_count, acc])\n",
    "                    self._save_checkpoint(save_path, epoch, batch_idx)\n",
    "                \n",
    "                del inputs, labels, outputs, loss\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_samples = 0\n",
    "        num_classes = self.model.num_classes\n",
    "        mismatches_per_class = torch.zeros(num_classes, device=self.device)\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                # Get binary predictions (0 or 1) using threshold\n",
    "                predicted = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "\n",
    "                all_preds.append(predicted.cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "                \n",
    "                # Track mismatches per class\n",
    "                mismatches_per_class += (predicted != labels).sum(dim=0).float()\n",
    "                total_samples += inputs.size(0)  # Batch size\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat(all_preds)\n",
    "        all_labels = torch.cat(all_labels)\n",
    "\n",
    "        f1 = F1Score(task='multilabel', num_labels=num_classes, average='macro')\n",
    "        f1_score = f1(all_preds, all_labels)\n",
    "\n",
    "        # Calculate Hamming loss per class\n",
    "        hamming_loss_per_class = mismatches_per_class.cpu().numpy() / total_samples\n",
    "        overall_hamming_loss = mismatches_per_class.sum().item() / (total_samples * num_classes)\n",
    "\n",
    "        return {\n",
    "            \"f1\": f1_score.item(),\n",
    "            \"overall\": overall_hamming_loss,\n",
    "            \"per_class\": hamming_loss_per_class\n",
    "        }\n",
    "\n",
    "    def _update_parameters(self):\n",
    "        \"\"\"Update model parameters with gradient clipping\"\"\"\n",
    "        self.scaler.unscale_(self.optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "        self.scaler.step(self.optimizer)\n",
    "        self.scaler.update()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def _save_checkpoint(self, path, epoch, batch_idx):\n",
    "        \"\"\"Save model and training state\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'batch': batch_idx,\n",
    "            'batch_count': self.batch_count,\n",
    "            'checkpoint_interval': self.checkpoint_interval,\n",
    "            'model_state': self.model.state_dict(),\n",
    "            'optimizer_state': self.optimizer.state_dict(),\n",
    "            'loss_history': self.loss_history,\n",
    "            'acc_history': self.acc_history,\n",
    "            'scaler_state': self.scaler.state_dict()\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, f\"{path}/checkpoint_ep{epoch}_b{batch_idx}.pt\")\n",
    "        print(f\"\\nCheckpoint saved at epoch {epoch+1} batch {batch_idx+1}\")\n",
    "\n",
    "        # Save loss history separately for easy plotting\n",
    "        np.save(f\"{path}/loss_history.npy\", np.array(self.loss_history))\n",
    "        np.save(f\"{path}/acc_history.npy\", np.array(self.acc_history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Go Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_dataset = ECGDataset(diagnoses='data/diagnoses_cut.csv', transform=NormalizeECG())\n",
    "train_dataset, test_dataset, val_dataset = random_split(\n",
    "                                            ecg_dataset, [len(ecg_dataset) - 1000, 500, 500], \n",
    "                                            torch.Generator().manual_seed(42))\n",
    "\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECGCombined(d_input=12, d_model=64, num_classes=2, nhead=4, num_encoder_layers=2, dim_feedforward=128).to(device)\n",
    "trainer = Trainer(model, device, accum_steps=16, lr=1e-5)\n",
    "trainer.train(train_dataloader, test_dataloader, num_epochs=1, save_path=\"training_progress/cut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume from a checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_from = \"training_progress/cut/checkpoint_ep0_b2559.pt\"\n",
    "\n",
    "model = ECGCombined(d_input=12, d_model=64, num_classes=2, nhead=4, num_encoder_layers=2, dim_feedforward=128).to(device)\n",
    "trainer = Trainer(model, device, accum_steps=16, lr=1e-8, resume_checkpoint=resume_from)\n",
    "trainer.train(train_dataloader, test_dataloader, num_epochs=1, save_path=\"training_progress/cut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_history = np.load('training_progress/cut/acc_history.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss history plot\n",
    "loss_history = np.load('training_progress/cut/loss_history.npy', allow_pickle=True)  # Load loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score plot\n",
    "x = np.array([i[0] for i in acc_history])\n",
    "\n",
    "f1 = np.array([i[1]['f1'] for i in acc_history])\n",
    "plt.plot(x, f1)\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamming accuracy plot\n",
    "classes_acc = np.array([epoch[1]['per_class'] for epoch in acc_history])\n",
    "plt.plot(x, classes_acc)\n",
    "plt.legend([f'Class {i}' for i in range(2)], loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Hamming Loss')\n",
    "plt.yscale('log')\n",
    "plt.title('Hamming Loss per class')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
